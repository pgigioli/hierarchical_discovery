{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import pickle\n",
    "\n",
    "from src import datasets\n",
    "from src import data_utils\n",
    "from src import models\n",
    "from src import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'dataset' : 'newsgroups',\n",
    "    'val_split' : 0.1,\n",
    "    'vocab_size' : 30000,\n",
    "    'max_len' : 100,\n",
    "    'embedding_dim' : 100,\n",
    "    'hidden_size' : 128,\n",
    "    'straight_through' : False,\n",
    "    'dropout_keep_prob' : 0.5,\n",
    "    'use_attn' : True,\n",
    "    'n_layers' : 1,\n",
    "    'hierarchies' : [6, 6, 6],\n",
    "    'batch_size' : 32,\n",
    "    'n_epochs' : 200,\n",
    "    'learning_rate' : 0.001,\n",
    "    'gumbel_temperature' : 1.0,\n",
    "    'discrete_loss_weight' : 1.0,\n",
    "    'continuous_loss_weight' : 1.0,\n",
    "    'gumbel_loss_weight' : 0.0,\n",
    "    'orthogonality_loss_weight' : 0.0,\n",
    "    'mse_loss_weight' : 0.0,\n",
    "    'trainable_embeddings' : True,\n",
    "    'rnn_cell' : tf.contrib.rnn.GRUCell,\n",
    "    'device' : 0,\n",
    "    'use_cuda' : True,\n",
    "    'debug_mode' : False,\n",
    "    'display_interval' : 200,\n",
    "    'val_interval' : 1000,\n",
    "    'deploy_interval' : 5000,\n",
    "    'weights_file' : None, #'train_results/RNNClassifier_01102019_160346/weights/RNNClassifier_weights_epoch_65_itr_21000',\n",
    "    'finetune' : False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['dataset'] == 'newsgroups':\n",
    "    data = datasets.NewsGroup(params['val_split'])\n",
    "elif params['dataset'] == 'reuters8':\n",
    "    data = datasets.Reuters('data/reuters', 8, params['val_split'])\n",
    "elif params['dataset'] == 'reuters52':\n",
    "    data = datasets.Reuters('data/reuters', 52, params['val_split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=stopwords.words('english') + list(punctuation))\n",
    "tfidf.fit(data.train_texts + data.val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = data_utils.SequenceVectorizer(vocab=None, lowercase=True, keep_digits=True, keep_punctuations=False, punctuations_to_keep=['.', '?', '!'], \n",
    "                 vocab_size=params['vocab_size'], max_sequence_len=params['max_len'], pad_token='PAD', unk_token='UNK',  eos_token=None, go_token=None)\n",
    "vectorizer.fit(data.train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Example:\n",
    "    def __init__(self, text, label, vectorizer):\n",
    "        self.text = text\n",
    "        self.label = label\n",
    "        self.ids, self.real_len = vectorizer.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = [Example(text, label, vectorizer) for text, label in zip(data.train_texts, data.train_labels)]\n",
    "val_examples = [Example(text, label, vectorizer) for text, label in zip(data.val_texts, data.val_labels)]\n",
    "test_examples = [Example(text, label, vectorizer) for text, label in zip(data.test_texts, data.test_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batcher = data_utils.DataBatcher(train_examples, params['batch_size'])\n",
    "val_batcher = data_utils.DataBatcher(val_examples, params['batch_size'])\n",
    "test_batcher = data_utils.DataBatcher(test_examples, params['batch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"{}\".format(params['device'])\n",
    "device_name = '/gpu:{}'.format(params['device']) if params['use_cuda'] else '/cpu:{}'.format(params['device'])\n",
    "\n",
    "tf.reset_default_graph()\n",
    "graph = tf.Graph()\n",
    "with graph.as_default(), tf.device(device_name):\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "    model = models.DiscreteHierarchicalClassifier(\n",
    "        len(data.classes), \n",
    "        params['vocab_size'], \n",
    "        params['max_len'], \n",
    "        learning_rate=params['learning_rate'],\n",
    "        embedding_dim=params['embedding_dim'], \n",
    "        hidden_size=params['hidden_size'], \n",
    "        straight_through=params['straight_through'],\n",
    "        use_attn=params['use_attn'], \n",
    "        n_layers=params['n_layers'], \n",
    "        hierarchies=params['hierarchies'],\n",
    "        pretrained_embeddings=None, \n",
    "        trainable_embeddings=params['trainable_embeddings'], \n",
    "        rnn_cell=params['rnn_cell'],\n",
    "        class_weights=data.class_weights\n",
    "    )\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    pretrain_loader = tf.train.Saver(var_list=model.pretrain_vars)\n",
    "    saver = tf.train.Saver(var_list=tf.trainable_variables(), max_to_keep=10)\n",
    "\n",
    "    functions.count_params(tf.trainable_variables())\n",
    "    for var in tf.trainable_variables(): print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not params['debug_mode']:\n",
    "    results_dir = functions.prepare_results_dir(model.__class__.__name__)\n",
    "    weights_dir = os.path.join(results_dir, 'weights')\n",
    "    if not os.path.exists(weights_dir): os.makedirs(weights_dir)\n",
    "    log_file = os.path.join(results_dir, 'train_log.txt')\n",
    "    log_description = \"\\n\".join([\"{} : {}\".format(k, v) for k, v in params.items()])\n",
    "    log = open(log_file, 'w')\n",
    "    log.close()\n",
    "    functions.write_to_log(log_description, log_file)\n",
    "    pickle.dump(params, open(os.path.join(results_dir, 'params.pickle'), 'wb'))\n",
    "    pickle.dump(vectorizer, open(os.path.join(results_dir, 'vectorizer.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gumbel_temperature_schedule = lambda x, itr : max(x, 1.0 - (1.0-x)*(max(itr, 10000)-10000)/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_batcher):\n",
    "    discrete_loss_weight, continuous_loss_weight = params['discrete_loss_weight'], params['continuous_loss_weight']\n",
    "    loss, discrete_loss, continuous_loss, gumbel_loss, orth_loss, mse_loss, discrete_acc, continuous_acc = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    pred_hier_labels, actual_hier_labels = [], []\n",
    "    for i in range(int(np.ceil(len(data_batcher.data)/data_batcher.batch_size))):\n",
    "        batch = data_batcher.next_batch()\n",
    "        inputs = [example.ids for example in batch]\n",
    "        input_lens = [example.real_len for example in batch]\n",
    "        input_targets = [example.label for example in batch]\n",
    "\n",
    "        if params['discrete_loss_weight'] == 'random':\n",
    "            discrete_loss_weight = 1.0\n",
    "        if params['continuous_loss_weight'] == 'random':\n",
    "            continuous_loss_weight = 1.0\n",
    "\n",
    "        feed_dict = {\n",
    "            model.inputs : inputs,\n",
    "            model.input_lens : input_lens,\n",
    "            model.targets : input_targets,\n",
    "            model.dropout_keep_prob : 1.0,\n",
    "            model.gumbel_temperature : gumbel_temperature_schedule(params['gumbel_temperature'], itr),\n",
    "            model.discrete_loss_weight : discrete_loss_weight,\n",
    "            model.continuous_loss_weight : continuous_loss_weight,\n",
    "            model.gumbel_loss_weight : params['gumbel_loss_weight'],\n",
    "            model.orthogonality_loss_weight : params['orthogonality_loss_weight'],\n",
    "            model.mse_loss_weight : params['mse_loss_weight']\n",
    "        }\n",
    "        (batch_softmaxes, batch_loss, batch_discrete_loss, batch_continuous_loss, batch_gumbel_loss, batch_orth_loss, \n",
    "         batch_mse_loss, batch_discrete_acc, batch_continuous_acc) = sess.run(\n",
    "            [model.gumbel_onehots, model.loss, model.discrete_loss, model.continuous_loss, model.gumbel_loss, \n",
    "             model.orthogonality_loss, model.mse_loss, model.discrete_accuracy, model.continuous_accuracy], feed_dict=feed_dict\n",
    "        )\n",
    "\n",
    "        pred_hier_labels += list(zip(*[np.argmax(x, axis=1) for x in batch_softmaxes]))\n",
    "        actual_hier_labels += [data.label_dict[l].split('.') for l in input_targets]\n",
    "\n",
    "        loss += (batch_loss - loss)/(i+1)\n",
    "        discrete_loss += (batch_discrete_loss - discrete_loss)/(i+1)\n",
    "        continuous_loss += (batch_continuous_loss - continuous_loss)/(i+1)\n",
    "        gumbel_loss += (batch_gumbel_loss - gumbel_loss)/(i+1)\n",
    "        orth_loss += (batch_orth_loss - orth_loss)/(i+1)\n",
    "        mse_loss += (batch_mse_loss - mse_loss)/(i+1)\n",
    "        discrete_acc += (batch_discrete_acc - discrete_acc)/(i+1)\n",
    "        continuous_acc += (batch_continuous_acc - continuous_acc)/(i+1)\n",
    "    hier_bcubed = functions.evaluate_hierarchical_bcubed(pred_hier_labels, actual_hier_labels)\n",
    "    return loss, discrete_loss, continuous_loss, gumbel_loss, orth_loss, mse_loss, discrete_acc, continuous_acc, hier_bcubed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)\n",
    "if params['weights_file'] != None:\n",
    "    pretrain_loader.restore(sess, params['weights_file'])\n",
    "    log_output = \"\\nTraining variables:\\n{}\\n\".format(model.finetune_vars)\n",
    "    print(log_output)\n",
    "    if not params['debug_mode']:\n",
    "        functions.write_to_log(log_output, log_file)\n",
    "\n",
    "best_loss, best_acc = 10e6, 0.0\n",
    "discrete_loss_weight, continuous_loss_weight = params['discrete_loss_weight'], params['continuous_loss_weight']\n",
    "while train_batcher.epoch < params['n_epochs']:\n",
    "    itr = tf.train.global_step(sess, model.global_step) + 1\n",
    "        \n",
    "    train_batch = train_batcher.next_batch()\n",
    "    inputs = [example.ids for example in train_batch]\n",
    "    input_lens = [example.real_len for example in train_batch]\n",
    "    input_targets = [example.label for example in train_batch]\n",
    "    \n",
    "    noise_switch = random.randint(0, 1)\n",
    "    if params['discrete_loss_weight'] == 'random':\n",
    "        discrete_loss_weight = noise_switch\n",
    "    if params['continuous_loss_weight'] == 'random':\n",
    "        continuous_loss_weight = 1-noise_switch\n",
    "    \n",
    "    feed_dict = {\n",
    "        model.inputs : inputs,\n",
    "        model.input_lens : input_lens,\n",
    "        model.targets : input_targets,\n",
    "        model.dropout_keep_prob : params['dropout_keep_prob'],\n",
    "        model.gumbel_temperature : gumbel_temperature_schedule(params['gumbel_temperature'], itr),\n",
    "        model.discrete_loss_weight : discrete_loss_weight,\n",
    "        model.continuous_loss_weight : continuous_loss_weight,\n",
    "        model.gumbel_loss_weight : params['gumbel_loss_weight'],\n",
    "        model.orthogonality_loss_weight : params['orthogonality_loss_weight'],\n",
    "        model.mse_loss_weight : params['mse_loss_weight']\n",
    "    }\n",
    "    \n",
    "    if params['finetune']:\n",
    "        _ = sess.run(model.finetune_optimizer, feed_dict=feed_dict)\n",
    "    else:\n",
    "        _ = sess.run(model.optimizer, feed_dict=feed_dict)\n",
    "    \n",
    "    if itr % params['display_interval'] == 0 or itr == 1: \n",
    "        (train_loss, train_discrete_loss, train_continuous_loss, train_gumbel_loss, train_orth_loss, \n",
    "         train_mse_loss, train_discrete_acc, train_continuous_acc, grad_norm) = sess.run(\n",
    "            [model.loss, model.discrete_loss, model.continuous_loss, model.gumbel_loss, model.orthogonality_loss, model.mse_loss, \n",
    "             model.discrete_accuracy, model.continuous_accuracy, model.gradient_norm], feed_dict=feed_dict\n",
    "        )\n",
    "        \n",
    "        log_output = \"[{}, {:5d}] train loss: (batch: {:.4f}, discrete: {:.4f}, continuous: {:.4f}, gumbel: {:.4f}, orth: {:.4f}, mse: {:.4f}), \\\n",
    "discrete acc: {:.4f}, continuous acc: {:4f}, grad_norm: {:.4f}\".format(train_batcher.epoch, itr, train_loss, train_discrete_loss, train_continuous_loss, \n",
    "                                                               train_gumbel_loss, train_orth_loss, train_mse_loss, train_discrete_acc, train_continuous_acc, grad_norm)\n",
    "        print(log_output)\n",
    "        if not params['debug_mode']:\n",
    "            functions.write_to_log(log_output, log_file)\n",
    "        \n",
    "    if itr % params['val_interval'] == 0:\n",
    "        (val_loss, val_discrete_loss, val_continuous_loss, val_gumbel_loss, val_orth_loss, val_mse_loss, \n",
    "         val_discrete_acc, val_continuous_acc, val_hier_bcubed) = evaluate(model, val_batcher)\n",
    "        \n",
    "        log_output = \"Val - loss: {:.4f}, discrete loss: {:.4f}, continuous loss: {:.4f}, gumbel loss: {:.4f}, orth loss: {:4f}, mse loss: {:4f}, \\\n",
    "discrete acc: {:.4f}, continuous acc: {:.4f}\".format(val_loss, val_discrete_loss, val_continuous_loss, val_gumbel_loss, val_orth_loss, \n",
    "                                             val_mse_loss, val_discrete_acc, val_continuous_acc)\n",
    "        log_output += \"\\nhierarchical bcubed:\\n\"\n",
    "        for k, v in val_hier_bcubed.items(): log_output += '[{}] F1: {:.4f}, R: {:.4f}, P: {:.4f}\\n'.format(k, v['F1'], v['R'], v['P'])\n",
    "        print(log_output)\n",
    "        if not params['debug_mode']:\n",
    "            functions.write_to_log(log_output, log_file)\n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "        if val_continuous_acc > best_acc:\n",
    "            best_acc = val_continuous_acc\n",
    "            (test_loss, test_discrete_loss, test_continuous_loss, test_gumbel_loss, test_orth_loss, test_mse_loss, \n",
    "             test_discrete_acc, test_continuous_acc, test_hier_bcubed) = evaluate(model, test_batcher)\n",
    "            \n",
    "            log_output = \"Test - loss: {:.4f}, discrete loss: {:.4f}, continuous loss: {:.4f}, gumbel loss: {:.4f}, orth loss: {:4f}, mse loss: {:4f}, \\\n",
    "discrete acc: {:.4f}, continuous acc: {:.4f}\".format(test_loss, test_discrete_loss, test_continuous_loss, test_gumbel_loss, test_orth_loss, \n",
    "                                             test_mse_loss, test_discrete_acc, test_continuous_acc)\n",
    "            log_output += \"\\nhierarchical bcubed:\\n\"\n",
    "            for k, v in test_hier_bcubed.items(): log_output += '[{}] F1: {:.4f}, R: {:.4f}, P: {:.4f}\\n'.format(k, v['F1'], v['R'], v['P'])\n",
    "            print(log_output)\n",
    "            if not params['debug_mode']:\n",
    "                functions.write_to_log(log_output, log_file)\n",
    "            \n",
    "            if not params['debug_mode']:\n",
    "                weights_prefix = \"{}_weights_epoch_{}_itr_{}\".format(model.__class__.__name__, train_batcher.epoch, itr)\n",
    "                log_output = \"Weights saved in file: {}\\n\".format(os.path.join(weights_dir, weights_prefix))\n",
    "                print(log_output)\n",
    "                if not params['debug_mode']:\n",
    "                    functions.write_to_log(log_output, log_file)\n",
    "                saver.save(sess, os.path.join(weights_dir, weights_prefix))\n",
    "        \n",
    "    if itr % params['deploy_interval'] == 0:\n",
    "        softmaxes, targets, texts = [], [], []\n",
    "        for i in range(int(np.ceil(len(val_batcher.data)/val_batcher.batch_size))):\n",
    "            val_batch = val_batcher.next_batch()\n",
    "            input_texts = [example.text for example in val_batch]\n",
    "            inputs = [example.ids for example in val_batch]\n",
    "            input_lens = [example.real_len for example in val_batch]\n",
    "            input_targets = [example.label for example in val_batch]\n",
    "            \n",
    "            feed_dict = {\n",
    "                model.inputs : inputs,\n",
    "                model.input_lens : input_lens,\n",
    "                model.dropout_keep_prob : 1.0,\n",
    "                model.gumbel_temperature : 0.1\n",
    "            }\n",
    "            softmax = sess.run(model.gumbel_onehots, feed_dict=feed_dict)\n",
    "            softmaxes.append(softmax)\n",
    "            targets += input_targets\n",
    "            texts += input_texts\n",
    "            \n",
    "        softmaxes = [np.concatenate(s, axis=0) for s in list(zip(*softmaxes))]\n",
    "        hierarchy_results = []\n",
    "        for level, softmax in enumerate(softmaxes):\n",
    "            log_output = '\\nHierarchy #{}\\n'.format(level)\n",
    "            hierarchy_dict = dict([(i, np.zeros(len(data.classes), dtype=int)) for i in range(softmax.shape[-1])])\n",
    "            label_assignment_dict = dict([(data.label_dict[i], np.zeros(softmax.shape[-1], dtype=int)) for i in range(len(data.classes))])\n",
    "            keywords_dict = dict([(i, '') for i in range(softmax.shape[-1])])\n",
    "            for c, lbl, txt in zip(np.argmax(softmax, axis=1), targets, texts):\n",
    "                hierarchy_dict[c][lbl] += 1\n",
    "                label_assignment_dict[data.label_dict[lbl]][c] += 1\n",
    "                keywords_dict[c] += ' ' + txt\n",
    "            log_output += 'Label Distributions:\\n'\n",
    "            for k, v in hierarchy_dict.items(): log_output += '{}: {}\\n'.format(k, list(v))\n",
    "            hierarchy_results.append(hierarchy_dict)\n",
    "            \n",
    "            log_output += '\\nHierarchy Assignments:\\n'\n",
    "            for k, v in sorted(list(label_assignment_dict.items()), key=lambda x: np.argmax(x[1])): log_output += '{}: {} ==> {}\\n'.format(k, list(v), np.argmax(list(v)))\n",
    "            \n",
    "            log_output += '\\nKeywords:\\n'\n",
    "            for k, v in keywords_dict.items(): log_output += '{}: {}\\n'.format(k, functions.get_important_words(v, tfidf, max_n=5))\n",
    "            \n",
    "            print(log_output)\n",
    "            if not params['debug_mode']:\n",
    "                functions.write_to_log(log_output, log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
